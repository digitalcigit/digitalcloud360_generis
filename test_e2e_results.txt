============================= test session starts ==============================
platform linux -- Python 3.11.14, pytest-9.0.2, pluggy-1.6.0
rootdir: /app
configfile: pytest.ini
plugins: anyio-4.12.0, mock-3.15.1, Faker-39.0.0, asyncio-1.3.0, langsmith-0.5.0
asyncio: mode=Mode.AUTO, debug=False, asyncio_default_fixture_loop_scope=function, asyncio_default_test_loop_scope=function
collected 1 item

tests/test_e2e/test_coaching_flow.py E                                   [100%]

==================================== ERRORS ====================================
_ ERROR at setup of TestCoachingFlowE2E.test_full_coaching_to_site_generation __

self = <sqlalchemy.dialects.postgresql.asyncpg.AsyncAdapt_asyncpg_cursor object at 0x7f562c7fe380>
operation = '\nCREATE TABLE user_embeddings (\n\tuser_id INTEGER NOT NULL, \n\tbrief_id VARCHAR NOT NULL, \n\tembedding VECTOR(153...d_at TIMESTAMP WITHOUT TIME ZONE NOT NULL, \n\tPRIMARY KEY (id), \n\tFOREIGN KEY(user_id) REFERENCES users (id)\n)\n\n'
parameters = ()

    async def _prepare_and_execute(self, operation, parameters):
        adapt_connection = self._adapt_connection
    
        async with adapt_connection._execute_mutex:
            if not adapt_connection._started:
                await adapt_connection._start_transaction()
    
            if parameters is None:
                parameters = ()
    
            try:
                prepared_stmt, attributes = await adapt_connection._prepare(
                    operation, self._invalidate_schema_cache_asof
                )
    
                if attributes:
                    self.description = [
                        (
                            attr.name,
                            attr.type.oid,
                            None,
                            None,
                            None,
                            None,
                            None,
                        )
                        for attr in attributes
                    ]
                else:
                    self.description = None
    
                if self.server_side:
                    self._cursor = await prepared_stmt.cursor(*parameters)
                    self.rowcount = -1
                else:
>                   self._rows = deque(await prepared_stmt.fetch(*parameters))
                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

/usr/local/lib/python3.11/site-packages/sqlalchemy/dialects/postgresql/asyncpg.py:550: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <asyncpg.prepared_stmt.PreparedStatement object at 0x7f562c70f0b0>
timeout = None, args = ()

    @connresource.guarded
    async def fetch(self, *args, timeout=None):
        r"""Execute the statement and return a list of :class:`Record` objects.
    
        :param str query: Query text
        :param args: Query arguments
        :param float timeout: Optional timeout value in seconds.
    
        :return: A list of :class:`Record` instances.
        """
>       data = await self.__bind_execute(args, 0, timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

/usr/local/lib/python3.11/site-packages/asyncpg/prepared_stmt.py:176: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <asyncpg.prepared_stmt.PreparedStatement object at 0x7f562c70f0b0>
args = (), limit = 0, timeout = None

    async def __bind_execute(self, args, limit, timeout):
>       data, status, _ = await self.__do_execute(
            lambda protocol: protocol.bind_execute(
                self._state, args, '', limit, True, timeout))

/usr/local/lib/python3.11/site-packages/asyncpg/prepared_stmt.py:241: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <asyncpg.prepared_stmt.PreparedStatement object at 0x7f562c70f0b0>
executor = <function PreparedStatement.__bind_execute.<locals>.<lambda> at 0x7f562c701b20>

    async def __do_execute(self, executor):
        protocol = self._connection._protocol
        try:
>           return await executor(protocol)
                   ^^^^^^^^^^^^^^^^^^^^^^^^

/usr/local/lib/python3.11/site-packages/asyncpg/prepared_stmt.py:230: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   asyncpg.exceptions.UndefinedObjectError: type "vector" does not exist

asyncpg/protocol/protocol.pyx:207: UndefinedObjectError

The above exception was the direct cause of the following exception:

self = <sqlalchemy.engine.base.Connection object at 0x7f562c8c4a50>
dialect = <sqlalchemy.dialects.postgresql.asyncpg.PGDialect_asyncpg object at 0x7f562c8fee10>
context = <sqlalchemy.dialects.postgresql.asyncpg.PGExecutionContext_asyncpg object at 0x7f562c4d4a90>
statement = <sqlalchemy.dialects.postgresql.base.PGDDLCompiler object at 0x7f562c4d6b10>
parameters = [()]

    def _exec_single_context(
        self,
        dialect: Dialect,
        context: ExecutionContext,
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
    ) -> CursorResult[Any]:
        """continue the _execute_context() method for a single DBAPI
        cursor.execute() or cursor.executemany() call.
    
        """
        if dialect.bind_typing is BindTyping.SETINPUTSIZES:
            generic_setinputsizes = context._prepare_set_input_sizes()
    
            if generic_setinputsizes:
                try:
                    dialect.do_set_input_sizes(
                        context.cursor, generic_setinputsizes, context
                    )
                except BaseException as e:
                    self._handle_dbapi_exception(
                        e, str(statement), parameters, None, context
                    )
    
        cursor, str_statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )
    
        effective_parameters: Optional[_AnyExecuteParams]
    
        if not context.executemany:
            effective_parameters = parameters[0]
        else:
            effective_parameters = parameters
    
        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                str_statement, effective_parameters = fn(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
        if self._echo:
            self._log_info(str_statement)
    
            stats = context._get_cache_stats()
    
            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        effective_parameters,
                        batches=10,
                        ismulti=context.executemany,
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]",
                    stats,
                )
    
        evt_handled: bool = False
        try:
            if context.execute_style is ExecuteStyle.EXECUTEMANY:
                effective_parameters = cast(
                    "_CoreMultiExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor,
                        str_statement,
                        effective_parameters,
                        context,
                    )
            elif not effective_parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, str_statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, str_statement, context
                    )
            else:
                effective_parameters = cast(
                    "_CoreSingleExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
>                   self.dialect.do_execute(
                        cursor, str_statement, effective_parameters, context
                    )

/usr/local/lib/python3.11/site-packages/sqlalchemy/engine/base.py:1967: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.asyncpg.PGDialect_asyncpg object at 0x7f562c8fee10>
cursor = <sqlalchemy.dialects.postgresql.asyncpg.AsyncAdapt_asyncpg_cursor object at 0x7f562c7fe380>
statement = '\nCREATE TABLE user_embeddings (\n\tuser_id INTEGER NOT NULL, \n\tbrief_id VARCHAR NOT NULL, \n\tembedding VECTOR(153...d_at TIMESTAMP WITHOUT TIME ZONE NOT NULL, \n\tPRIMARY KEY (id), \n\tFOREIGN KEY(user_id) REFERENCES users (id)\n)\n\n'
parameters = ()
context = <sqlalchemy.dialects.postgresql.asyncpg.PGExecutionContext_asyncpg object at 0x7f562c4d4a90>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)

/usr/local/lib/python3.11/site-packages/sqlalchemy/engine/default.py:952: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.asyncpg.AsyncAdapt_asyncpg_cursor object at 0x7f562c7fe380>
operation = '\nCREATE TABLE user_embeddings (\n\tuser_id INTEGER NOT NULL, \n\tbrief_id VARCHAR NOT NULL, \n\tembedding VECTOR(153...d_at TIMESTAMP WITHOUT TIME ZONE NOT NULL, \n\tPRIMARY KEY (id), \n\tFOREIGN KEY(user_id) REFERENCES users (id)\n)\n\n'
parameters = ()

    def execute(self, operation, parameters=None):
>       self._adapt_connection.await_(
            self._prepare_and_execute(operation, parameters)
        )

/usr/local/lib/python3.11/site-packages/sqlalchemy/dialects/postgresql/asyncpg.py:585: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

awaitable = <coroutine object AsyncAdapt_asyncpg_cursor._prepare_and_execute at 0x7f562c9471c0>

    def await_only(awaitable: Awaitable[_T]) -> _T:
        """Awaits an async function in a sync method.
    
        The sync method must be inside a :func:`greenlet_spawn` context.
        :func:`await_only` calls cannot be nested.
    
        :param awaitable: The coroutine to call.
    
        """
        # this is called in the context greenlet while running fn
        current = getcurrent()
        if not getattr(current, "__sqlalchemy_greenlet_provider__", False):
            _safe_cancel_awaitable(awaitable)
    
            raise exc.MissingGreenlet(
                "greenlet_spawn has not been called; can't call await_only() "
                "here. Was IO attempted in an unexpected place?"
            )
    
        # returns the control to the driver greenlet passing it
        # a coroutine to run. Once the awaitable is done, the driver greenlet
        # switches back to this greenlet with the result of awaitable that is
        # then returned to the caller (or raised as error)
>       return current.parent.switch(awaitable)  # type: ignore[no-any-return,attr-defined] # noqa: E501
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

/usr/local/lib/python3.11/site-packages/sqlalchemy/util/_concurrency_py3k.py:132: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <bound method MetaData.create_all of MetaData()>, _require_await = False
args = (<sqlalchemy.engine.base.Connection object at 0x7f562c8c4a50>,)
kwargs = {}
context = <_AsyncIoGreenlet object at 0x7f562c81e880 (otid=0x7f564645ea90) dead>
switch_occurred = True
result = <coroutine object AsyncAdapt_asyncpg_cursor._prepare_and_execute at 0x7f562c9471c0>
value = None

    async def greenlet_spawn(
        fn: Callable[..., _T],
        *args: Any,
        _require_await: bool = False,
        **kwargs: Any,
    ) -> _T:
        """Runs a sync function ``fn`` in a new greenlet.
    
        The sync function can then use :func:`await_only` to wait for async
        functions.
    
        :param fn: The sync callable to call.
        :param \\*args: Positional arguments to pass to the ``fn`` callable.
        :param \\*\\*kwargs: Keyword arguments to pass to the ``fn`` callable.
        """
    
        result: Any
        context = _AsyncIoGreenlet(fn, getcurrent())
        # runs the function synchronously in gl greenlet. If the execution
        # is interrupted by await_only, context is not dead and result is a
        # coroutine to wait. If the context is dead the function has
        # returned, and its result can be returned.
        switch_occurred = False
        result = context.switch(*args, **kwargs)
        while not context.dead:
            switch_occurred = True
            try:
                # wait for a coroutine from await_only and then return its
                # result back to it.
>               value = await result
                        ^^^^^^^^^^^^

/usr/local/lib/python3.11/site-packages/sqlalchemy/util/_concurrency_py3k.py:196: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.asyncpg.AsyncAdapt_asyncpg_cursor object at 0x7f562c7fe380>
operation = '\nCREATE TABLE user_embeddings (\n\tuser_id INTEGER NOT NULL, \n\tbrief_id VARCHAR NOT NULL, \n\tembedding VECTOR(153...d_at TIMESTAMP WITHOUT TIME ZONE NOT NULL, \n\tPRIMARY KEY (id), \n\tFOREIGN KEY(user_id) REFERENCES users (id)\n)\n\n'
parameters = ()

    async def _prepare_and_execute(self, operation, parameters):
        adapt_connection = self._adapt_connection
    
        async with adapt_connection._execute_mutex:
            if not adapt_connection._started:
                await adapt_connection._start_transaction()
    
            if parameters is None:
                parameters = ()
    
            try:
                prepared_stmt, attributes = await adapt_connection._prepare(
                    operation, self._invalidate_schema_cache_asof
                )
    
                if attributes:
                    self.description = [
                        (
                            attr.name,
                            attr.type.oid,
                            None,
                            None,
                            None,
                            None,
                            None,
                        )
                        for attr in attributes
                    ]
                else:
                    self.description = None
    
                if self.server_side:
                    self._cursor = await prepared_stmt.cursor(*parameters)
                    self.rowcount = -1
                else:
                    self._rows = deque(await prepared_stmt.fetch(*parameters))
                    status = prepared_stmt.get_statusmsg()
    
                    reg = re.match(
                        r"(?:SELECT|UPDATE|DELETE|INSERT \d+) (\d+)",
                        status or "",
                    )
                    if reg:
                        self.rowcount = int(reg.group(1))
                    else:
                        self.rowcount = -1
    
            except Exception as error:
>               self._handle_exception(error)

/usr/local/lib/python3.11/site-packages/sqlalchemy/dialects/postgresql/asyncpg.py:563: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.asyncpg.AsyncAdapt_asyncpg_cursor object at 0x7f562c7fe380>
error = UndefinedObjectError('type "vector" does not exist')

    def _handle_exception(self, error):
>       self._adapt_connection._handle_exception(error)

/usr/local/lib/python3.11/site-packages/sqlalchemy/dialects/postgresql/asyncpg.py:513: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <AdaptedConnection <asyncpg.connection.Connection object at 0x7f562c810e50>>
error = UndefinedObjectError('type "vector" does not exist')

    def _handle_exception(self, error):
        if self._connection.is_closed():
            self._transaction = None
            self._started = False
    
        if not isinstance(error, AsyncAdapt_asyncpg_dbapi.Error):
            exception_mapping = self.dbapi._asyncpg_error_translate
    
            for super_ in type(error).__mro__:
                if super_ in exception_mapping:
                    translated_error = exception_mapping[super_](
                        "%s: %s" % (type(error), error)
                    )
                    translated_error.pgcode = translated_error.sqlstate = (
                        getattr(error, "sqlstate", None)
                    )
>                   raise translated_error from error
E                   sqlalchemy.dialects.postgresql.asyncpg.AsyncAdapt_asyncpg_dbapi.ProgrammingError: <class 'asyncpg.exceptions.UndefinedObjectError'>: type "vector" does not exist

/usr/local/lib/python3.11/site-packages/sqlalchemy/dialects/postgresql/asyncpg.py:797: ProgrammingError

The above exception was the direct cause of the following exception:

self = <Coroutine test_full_coaching_to_site_generation>

    def setup(self) -> None:
        runner_fixture_id = f"_{self._loop_scope}_scoped_runner"
        if runner_fixture_id not in self.fixturenames:
            self.fixturenames.append(runner_fixture_id)
>       return super().setup()
               ^^^^^^^^^^^^^^^

/usr/local/lib/python3.11/site-packages/pytest_asyncio/plugin.py:458: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fixturedef = <FixtureDef argname='test_engine_docker' scope='function' baseid='tests'>
request = <SubRequest 'test_engine_docker' for <Coroutine test_full_coaching_to_site_generation>>

    @pytest.hookimpl(wrapper=True)
    def pytest_fixture_setup(fixturedef: FixtureDef, request) -> object | None:
        asyncio_mode = _get_asyncio_mode(request.config)
        if not _is_asyncio_fixture_function(fixturedef.func):
            if asyncio_mode == Mode.STRICT:
                # Ignore async fixtures without explicit asyncio mark in strict mode
                # This applies to pytest_trio fixtures, for example
                return (yield)
            if not _is_coroutine_or_asyncgen(fixturedef.func):
                return (yield)
        default_loop_scope = request.config.getini("asyncio_default_fixture_loop_scope")
        loop_scope = (
            getattr(fixturedef.func, "_loop_scope", None)
            or default_loop_scope
            or fixturedef.scope
        )
        runner_fixture_id = f"_{loop_scope}_scoped_runner"
        runner = request.getfixturevalue(runner_fixture_id)
        synchronizer = _fixture_synchronizer(fixturedef, runner, request)
        _make_asyncio_fixture_function(synchronizer, loop_scope)
        with MonkeyPatch.context() as c:
            c.setattr(fixturedef, "func", synchronizer)
>           hook_result = yield
                          ^^^^^

/usr/local/lib/python3.11/site-packages/pytest_asyncio/plugin.py:743: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (), kwargs = {}
setup = <function _wrap_asyncgen_fixture.<locals>._asyncgen_fixture_wrapper.<locals>.setup at 0x7f562c85c720>

    @functools.wraps(fixture_function)
    def _asyncgen_fixture_wrapper(
        *args: AsyncGenFixtureParams.args,
        **kwargs: AsyncGenFixtureParams.kwargs,
    ):
        gen_obj = fixture_function(*args, **kwargs)
    
        async def setup():
            res = await gen_obj.__anext__()
            return res
    
        context = contextvars.copy_context()
>       result = runner.run(setup(), context=context)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

/usr/local/lib/python3.11/site-packages/pytest_asyncio/plugin.py:313: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <asyncio.runners.Runner object at 0x7f562c8d6790>
coro = <coroutine object _wrap_asyncgen_fixture.<locals>._asyncgen_fixture_wrapper.<locals>.setup at 0x7f562d0131d0>

    def run(self, coro, *, context=None):
        """Run a coroutine inside the embedded event loop."""
        if not coroutines.iscoroutine(coro):
            raise ValueError("a coroutine was expected, got {!r}".format(coro))
    
        if events._get_running_loop() is not None:
            # fail fast with short traceback
            raise RuntimeError(
                "Runner.run() cannot be called from a running event loop")
    
        self._lazy_init()
    
        if context is None:
            context = self._context
        task = self._loop.create_task(coro, context=context)
    
        if (threading.current_thread() is threading.main_thread()
            and signal.getsignal(signal.SIGINT) is signal.default_int_handler
        ):
            sigint_handler = functools.partial(self._on_sigint, main_task=task)
            try:
                signal.signal(signal.SIGINT, sigint_handler)
            except ValueError:
                # `signal.signal` may throw if `threading.main_thread` does
                # not support signals (e.g. embedded interpreter with signals
                # not registered - see gh-91880)
                sigint_handler = None
        else:
            sigint_handler = None
    
        self._interrupt_count = 0
        try:
>           return self._loop.run_until_complete(task)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

/usr/local/lib/python3.11/asyncio/runners.py:118: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <_UnixSelectorEventLoop running=False closed=False debug=False>
future = <Task finished name='Task-1' coro=<_wrap_asyncgen_fixture.<locals>._asyncgen_fixture_wrapper.<locals>.setup() done, de...stgresql.asyncpg.ProgrammingError) <class \'asyncpg.exceptions.UndefinedObjectError\'>: type "vector" does not exist')>

    def run_until_complete(self, future):
        """Run until the Future is done.
    
        If the argument is a coroutine, it is wrapped in a Task.
    
        WARNING: It would be disastrous to call run_until_complete()
        with the same coroutine twice -- it would wrap it in two
        different Tasks and that can't be good.
    
        Return the Future's result, or raise its exception.
        """
        self._check_closed()
        self._check_running()
    
        new_task = not futures.isfuture(future)
        future = tasks.ensure_future(future, loop=self)
        if new_task:
            # An exception is raised if the future didn't complete, so there
            # is no need to log the "destroy pending task" message
            future._log_destroy_pending = False
    
        future.add_done_callback(_run_until_complete_cb)
        try:
            self.run_forever()
        except:
            if new_task and future.done() and not future.cancelled():
                # The coroutine raised a BaseException. Consume the exception
                # to not log a warning, the caller doesn't have access to the
                # local task.
                future.exception()
            raise
        finally:
            future.remove_done_callback(_run_until_complete_cb)
        if not future.done():
            raise RuntimeError('Event loop stopped before Future completed.')
    
>       return future.result()
               ^^^^^^^^^^^^^^^

/usr/local/lib/python3.11/asyncio/base_events.py:654: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    async def setup():
>       res = await gen_obj.__anext__()
              ^^^^^^^^^^^^^^^^^^^^^^^^^

/usr/local/lib/python3.11/site-packages/pytest_asyncio/plugin.py:309: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    @pytest.fixture(scope="function")
    async def test_engine_docker():
        """Create a test SQLAlchemy engine using PostgreSQL DOCKER."""
        engine = create_async_engine(TEST_DATABASE_URL_DOCKER, echo=False)
    
        # Create tables
        async with engine.begin() as conn:
>           await conn.run_sync(Base.metadata.create_all)

tests/conftest_docker.py:39: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.ext.asyncio.engine.AsyncConnection object at 0x7f562c6c7a10>
fn = <bound method MetaData.create_all of MetaData()>, arg = (), kw = {}

    async def run_sync(
        self,
        fn: Callable[Concatenate[Connection, _P], _T],
        *arg: _P.args,
        **kw: _P.kwargs,
    ) -> _T:
        '''Invoke the given synchronous (i.e. not async) callable,
        passing a synchronous-style :class:`_engine.Connection` as the first
        argument.
    
        This method allows traditional synchronous SQLAlchemy functions to
        run within the context of an asyncio application.
    
        E.g.::
    
            def do_something_with_core(conn: Connection, arg1: int, arg2: str) -> str:
                """A synchronous function that does not require awaiting
    
                :param conn: a Core SQLAlchemy Connection, used synchronously
    
                :return: an optional return value is supported
    
                """
                conn.execute(some_table.insert().values(int_col=arg1, str_col=arg2))
                return "success"
    
    
            async def do_something_async(async_engine: AsyncEngine) -> None:
                """an async function that uses awaiting"""
    
                async with async_engine.begin() as async_conn:
                    # run do_something_with_core() with a sync-style
                    # Connection, proxied into an awaitable
                    return_code = await async_conn.run_sync(
                        do_something_with_core, 5, "strval"
                    )
                    print(return_code)
    
        This method maintains the asyncio event loop all the way through
        to the database connection by running the given callable in a
        specially instrumented greenlet.
    
        The most rudimentary use of :meth:`.AsyncConnection.run_sync` is to
        invoke methods such as :meth:`_schema.MetaData.create_all`, given
        an :class:`.AsyncConnection` that needs to be provided to
        :meth:`_schema.MetaData.create_all` as a :class:`_engine.Connection`
        object::
    
            # run metadata.create_all(conn) with a sync-style Connection,
            # proxied into an awaitable
            with async_engine.begin() as conn:
                await conn.run_sync(metadata.create_all)
    
        .. note::
    
            The provided callable is invoked inline within the asyncio event
            loop, and will block on traditional IO calls.  IO within this
            callable should only call into SQLAlchemy's asyncio database
            APIs which will be properly adapted to the greenlet context.
    
        .. seealso::
    
            :meth:`.AsyncSession.run_sync`
    
            :ref:`session_run_sync`
    
        '''  # noqa: E501
    
>       return await greenlet_spawn(
            fn, self._proxied, *arg, _require_await=False, **kw
        )

/usr/local/lib/python3.11/site-packages/sqlalchemy/ext/asyncio/engine.py:888: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <bound method MetaData.create_all of MetaData()>, _require_await = False
args = (<sqlalchemy.engine.base.Connection object at 0x7f562c8c4a50>,)
kwargs = {}
context = <_AsyncIoGreenlet object at 0x7f562c81e880 (otid=0x7f564645ea90) dead>
switch_occurred = True
result = <coroutine object AsyncAdapt_asyncpg_cursor._prepare_and_execute at 0x7f562c9471c0>
value = None

    async def greenlet_spawn(
        fn: Callable[..., _T],
        *args: Any,
        _require_await: bool = False,
        **kwargs: Any,
    ) -> _T:
        """Runs a sync function ``fn`` in a new greenlet.
    
        The sync function can then use :func:`await_only` to wait for async
        functions.
    
        :param fn: The sync callable to call.
        :param \\*args: Positional arguments to pass to the ``fn`` callable.
        :param \\*\\*kwargs: Keyword arguments to pass to the ``fn`` callable.
        """
    
        result: Any
        context = _AsyncIoGreenlet(fn, getcurrent())
        # runs the function synchronously in gl greenlet. If the execution
        # is interrupted by await_only, context is not dead and result is a
        # coroutine to wait. If the context is dead the function has
        # returned, and its result can be returned.
        switch_occurred = False
        result = context.switch(*args, **kwargs)
        while not context.dead:
            switch_occurred = True
            try:
                # wait for a coroutine from await_only and then return its
                # result back to it.
                value = await result
            except BaseException:
                # this allows an exception to be raised within
                # the moderated greenlet so that it can continue
                # its expected flow.
>               result = context.throw(*sys.exc_info())
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

/usr/local/lib/python3.11/site-packages/sqlalchemy/util/_concurrency_py3k.py:201: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = MetaData()
bind = <sqlalchemy.engine.base.Connection object at 0x7f562c8c4a50>
tables = None, checkfirst = True

    def create_all(
        self,
        bind: _CreateDropBind,
        tables: Optional[_typing_Sequence[Table]] = None,
        checkfirst: bool = True,
    ) -> None:
        """Create all tables stored in this metadata.
    
        Conditional by default, will not attempt to recreate tables already
        present in the target database.
    
        :param bind:
          A :class:`.Connection` or :class:`.Engine` used to access the
          database.
    
        :param tables:
          Optional list of ``Table`` objects, which is a subset of the total
          tables in the ``MetaData`` (others are ignored).
    
        :param checkfirst:
          Defaults to True, don't issue CREATEs for tables already present
          in the target database.
    
        """
>       bind._run_ddl_visitor(
            ddl.SchemaGenerator, self, checkfirst=checkfirst, tables=tables
        )

/usr/local/lib/python3.11/site-packages/sqlalchemy/sql/schema.py:5928: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.engine.base.Connection object at 0x7f562c8c4a50>
visitorcallable = <class 'sqlalchemy.sql.ddl.SchemaGenerator'>
element = MetaData(), kwargs = {'checkfirst': True, 'tables': None}

    def _run_ddl_visitor(
        self,
        visitorcallable: Type[InvokeDDLBase],
        element: SchemaVisitable,
        **kwargs: Any,
    ) -> None:
        """run a DDL visitor.
    
        This method is only here so that the MockConnection can change the
        options given to the visitor so that "checkfirst" is skipped.
    
        """
        visitorcallable(
            dialect=self.dialect, connection=self, **kwargs
>       ).traverse_single(element)
          ^^^^^^^^^^^^^^^^^^^^^^^^

/usr/local/lib/python3.11/site-packages/sqlalchemy/engine/base.py:2467: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.sql.ddl.SchemaGenerator object at 0x7f562c7f59f0>
obj = MetaData(), kw = {}
v = <sqlalchemy.sql.ddl.SchemaGenerator object at 0x7f562c7f59f0>
meth = <bound method SchemaGenerator.visit_metadata of <sqlalchemy.sql.ddl.SchemaGenerator object at 0x7f562c7f59f0>>

    def traverse_single(self, obj: Visitable, **kw: Any) -> Any:
        for v in self.visitor_iterator:
            meth = getattr(v, "visit_%s" % obj.__visit_name__, None)
            if meth:
>               return meth(obj, **kw)
                       ^^^^^^^^^^^^^^^

/usr/local/lib/python3.11/site-packages/sqlalchemy/sql/visitors.py:661: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.sql.ddl.SchemaGenerator object at 0x7f562c7f59f0>
metadata = MetaData()

    def visit_metadata(self, metadata):
        if self.tables is not None:
            tables = self.tables
        else:
            tables = list(metadata.tables.values())
    
        collection = sort_tables_and_constraints(
            [t for t in tables if self._can_create_table(t)]
        )
    
        seq_coll = [
            s
            for s in metadata._sequences.values()
            if s.column is None and self._can_create_sequence(s)
        ]
    
        event_collection = [t for (t, fks) in collection if t is not None]
    
        with self.with_ddl_events(
            metadata,
            tables=event_collection,
            checkfirst=self.checkfirst,
        ):
            for seq in seq_coll:
                self.traverse_single(seq, create_ok=True)
    
            for table, fkcs in collection:
                if table is not None:
>                   self.traverse_single(
                        table,
                        create_ok=True,
                        include_foreign_key_constraints=fkcs,
                        _is_metadata_operation=True,
                    )

/usr/local/lib/python3.11/site-packages/sqlalchemy/sql/ddl.py:984: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.sql.ddl.SchemaGenerator object at 0x7f562c7f59f0>
obj = Table('user_embeddings', MetaData(), Column('user_id', Integer(), ForeignKey('users.id'), table=<user_embeddings>, nul...1a8c50; now>), default=ColumnElementColumnDefault(<sqlalchemy.sql.functions.now at 0x7f56451a9b50; now>)), schema=None)
kw = {'_is_metadata_operation': True, 'create_ok': True, 'include_foreign_key_constraints': {ForeignKeyConstraint(<sqlalche...c50; now>), default=ColumnElementColumnDefault(<sqlalchemy.sql.functions.now at 0x7f56451a9b50; now>)), schema=None))}}
v = <sqlalchemy.sql.ddl.SchemaGenerator object at 0x7f562c7f59f0>
meth = <bound method SchemaGenerator.visit_table of <sqlalchemy.sql.ddl.SchemaGenerator object at 0x7f562c7f59f0>>

    def traverse_single(self, obj: Visitable, **kw: Any) -> Any:
        for v in self.visitor_iterator:
            meth = getattr(v, "visit_%s" % obj.__visit_name__, None)
            if meth:
>               return meth(obj, **kw)
                       ^^^^^^^^^^^^^^^

/usr/local/lib/python3.11/site-packages/sqlalchemy/sql/visitors.py:661: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.sql.ddl.SchemaGenerator object at 0x7f562c7f59f0>
table = Table('user_embeddings', MetaData(), Column('user_id', Integer(), ForeignKey('users.id'), table=<user_embeddings>, nul...1a8c50; now>), default=ColumnElementColumnDefault(<sqlalchemy.sql.functions.now at 0x7f56451a9b50; now>)), schema=None)
create_ok = True
include_foreign_key_constraints = {ForeignKeyConstraint(<sqlalchemy.sql.base.ReadOnlyColumnCollection object at 0x7f562b0cc6d0>, None, table=Table('user...8c50; now>), default=ColumnElementColumnDefault(<sqlalchemy.sql.functions.now at 0x7f56451a9b50; now>)), schema=None))}
_is_metadata_operation = True

    def visit_table(
        self,
        table,
        create_ok=False,
        include_foreign_key_constraints=None,
        _is_metadata_operation=False,
    ):
        if not create_ok and not self._can_create_table(table):
            return
    
        with self.with_ddl_events(
            table,
            checkfirst=self.checkfirst,
            _is_metadata_operation=_is_metadata_operation,
        ):
            for column in table.columns:
                if column.default is not None:
                    self.traverse_single(column.default)
    
            if not self.dialect.supports_alter:
                # e.g., don't omit any foreign key constraints
                include_foreign_key_constraints = None
    
            CreateTable(
                table,
                include_foreign_key_constraints=(
                    include_foreign_key_constraints
                ),
>           )._invoke_with(self.connection)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

/usr/local/lib/python3.11/site-packages/sqlalchemy/sql/ddl.py:1022: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.sql.ddl.CreateTable object at 0x7f562c4c1890>
bind = <sqlalchemy.engine.base.Connection object at 0x7f562c8c4a50>

    def _invoke_with(self, bind):
        if self._should_execute(self.target, bind):
>           return bind.execute(self)
                   ^^^^^^^^^^^^^^^^^^

/usr/local/lib/python3.11/site-packages/sqlalchemy/sql/ddl.py:321: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.engine.base.Connection object at 0x7f562c8c4a50>
statement = <sqlalchemy.sql.ddl.CreateTable object at 0x7f562c4c1890>
parameters = None

    def execute(
        self,
        statement: Executable,
        parameters: Optional[_CoreAnyExecuteParams] = None,
        *,
        execution_options: Optional[CoreExecuteOptionsParameter] = None,
    ) -> CursorResult[Any]:
        r"""Executes a SQL statement construct and returns a
        :class:`_engine.CursorResult`.
    
        :param statement: The statement to be executed.  This is always
         an object that is in both the :class:`_expression.ClauseElement` and
         :class:`_expression.Executable` hierarchies, including:
    
         * :class:`_expression.Select`
         * :class:`_expression.Insert`, :class:`_expression.Update`,
           :class:`_expression.Delete`
         * :class:`_expression.TextClause` and
           :class:`_expression.TextualSelect`
         * :class:`_schema.DDL` and objects which inherit from
           :class:`_schema.ExecutableDDLElement`
    
        :param parameters: parameters which will be bound into the statement.
         This may be either a dictionary of parameter names to values,
         or a mutable sequence (e.g. a list) of dictionaries.  When a
         list of dictionaries is passed, the underlying statement execution
         will make use of the DBAPI ``cursor.executemany()`` method.
         When a single dictionary is passed, the DBAPI ``cursor.execute()``
         method will be used.
    
        :param execution_options: optional dictionary of execution options,
         which will be associated with the statement execution.  This
         dictionary can provide a subset of the options that are accepted
         by :meth:`_engine.Connection.execution_options`.
    
        :return: a :class:`_engine.Result` object.
    
        """
        distilled_parameters = _distill_params_20(parameters)
        try:
            meth = statement._execute_on_connection
        except AttributeError as err:
            raise exc.ObjectNotExecutableError(statement) from err
        else:
>           return meth(
                self,
                distilled_parameters,
                execution_options or NO_OPTIONS,
            )

/usr/local/lib/python3.11/site-packages/sqlalchemy/engine/base.py:1419: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.sql.ddl.CreateTable object at 0x7f562c4c1890>
connection = <sqlalchemy.engine.base.Connection object at 0x7f562c8c4a50>
distilled_params = (), execution_options = immutabledict({})

    def _execute_on_connection(
        self, connection, distilled_params, execution_options
    ):
>       return connection._execute_ddl(
            self, distilled_params, execution_options
        )

/usr/local/lib/python3.11/site-packages/sqlalchemy/sql/ddl.py:187: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.engine.base.Connection object at 0x7f562c8c4a50>
ddl = <sqlalchemy.sql.ddl.CreateTable object at 0x7f562c4c1890>
distilled_parameters = (), execution_options = immutabledict({})

    def _execute_ddl(
        self,
        ddl: ExecutableDDLElement,
        distilled_parameters: _CoreMultiExecuteParams,
        execution_options: CoreExecuteOptionsParameter,
    ) -> CursorResult[Any]:
        """Execute a schema.DDL object."""
    
        exec_opts = ddl._execution_options.merge_with(
            self._execution_options, execution_options
        )
    
        event_multiparams: Optional[_CoreMultiExecuteParams]
        event_params: Optional[_CoreSingleExecuteParams]
    
        if self._has_events or self.engine._has_events:
            (
                ddl,
                distilled_parameters,
                event_multiparams,
                event_params,
            ) = self._invoke_before_exec_event(
                ddl, distilled_parameters, exec_opts
            )
        else:
            event_multiparams = event_params = None
    
        schema_translate_map = exec_opts.get("schema_translate_map", None)
    
        dialect = self.dialect
    
        compiled = ddl.compile(
            dialect=dialect, schema_translate_map=schema_translate_map
        )
>       ret = self._execute_context(
            dialect,
            dialect.execution_ctx_cls._init_ddl,
            compiled,
            None,
            exec_opts,
            compiled,
        )

/usr/local/lib/python3.11/site-packages/sqlalchemy/engine/base.py:1530: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.engine.base.Connection object at 0x7f562c8c4a50>
dialect = <sqlalchemy.dialects.postgresql.asyncpg.PGDialect_asyncpg object at 0x7f562c8fee10>
constructor = <bound method DefaultExecutionContext._init_ddl of <class 'sqlalchemy.dialects.postgresql.asyncpg.PGExecutionContext_asyncpg'>>
statement = <sqlalchemy.dialects.postgresql.base.PGDDLCompiler object at 0x7f562c4d6b10>
parameters = None, execution_options = immutabledict({})
args = (<sqlalchemy.dialects.postgresql.base.PGDDLCompiler object at 0x7f562c4d6b10>,)
kw = {}, conn = <sqlalchemy.pool.base._ConnectionFairy object at 0x7f562c886090>
context = <sqlalchemy.dialects.postgresql.asyncpg.PGExecutionContext_asyncpg object at 0x7f562c4d4a90>

    def _execute_context(
        self,
        dialect: Dialect,
        constructor: Callable[..., ExecutionContext],
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
        execution_options: _ExecuteOptions,
        *args: Any,
        **kw: Any,
    ) -> CursorResult[Any]:
        """Create an :class:`.ExecutionContext` and execute, returning
        a :class:`_engine.CursorResult`."""
    
        if execution_options:
            yp = execution_options.get("yield_per", None)
            if yp:
                execution_options = execution_options.union(
                    {"stream_results": True, "max_row_buffer": yp}
                )
        try:
            conn = self._dbapi_connection
            if conn is None:
                conn = self._revalidate_connection()
    
            context = constructor(
                dialect, self, conn, execution_options, *args, **kw
            )
        except (exc.PendingRollbackError, exc.ResourceClosedError):
            raise
        except BaseException as e:
            self._handle_dbapi_exception(
                e, str(statement), parameters, None, None
            )
    
        if (
            self._transaction
            and not self._transaction.is_active
            or (
                self._nested_transaction
                and not self._nested_transaction.is_active
            )
        ):
            self._invalid_transaction()
    
        elif self._trans_context_manager:
            TransactionalContext._trans_ctx_check(self)
    
        if self._transaction is None:
            self._autobegin()
    
        context.pre_exec()
    
        if context.execute_style is ExecuteStyle.INSERTMANYVALUES:
            return self._exec_insertmany_context(dialect, context)
        else:
>           return self._exec_single_context(
                dialect, context, statement, parameters
            )

/usr/local/lib/python3.11/site-packages/sqlalchemy/engine/base.py:1846: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.engine.base.Connection object at 0x7f562c8c4a50>
dialect = <sqlalchemy.dialects.postgresql.asyncpg.PGDialect_asyncpg object at 0x7f562c8fee10>
context = <sqlalchemy.dialects.postgresql.asyncpg.PGExecutionContext_asyncpg object at 0x7f562c4d4a90>
statement = <sqlalchemy.dialects.postgresql.base.PGDDLCompiler object at 0x7f562c4d6b10>
parameters = [()]

    def _exec_single_context(
        self,
        dialect: Dialect,
        context: ExecutionContext,
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
    ) -> CursorResult[Any]:
        """continue the _execute_context() method for a single DBAPI
        cursor.execute() or cursor.executemany() call.
    
        """
        if dialect.bind_typing is BindTyping.SETINPUTSIZES:
            generic_setinputsizes = context._prepare_set_input_sizes()
    
            if generic_setinputsizes:
                try:
                    dialect.do_set_input_sizes(
                        context.cursor, generic_setinputsizes, context
                    )
                except BaseException as e:
                    self._handle_dbapi_exception(
                        e, str(statement), parameters, None, context
                    )
    
        cursor, str_statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )
    
        effective_parameters: Optional[_AnyExecuteParams]
    
        if not context.executemany:
            effective_parameters = parameters[0]
        else:
            effective_parameters = parameters
    
        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                str_statement, effective_parameters = fn(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
        if self._echo:
            self._log_info(str_statement)
    
            stats = context._get_cache_stats()
    
            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        effective_parameters,
                        batches=10,
                        ismulti=context.executemany,
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]",
                    stats,
                )
    
        evt_handled: bool = False
        try:
            if context.execute_style is ExecuteStyle.EXECUTEMANY:
                effective_parameters = cast(
                    "_CoreMultiExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor,
                        str_statement,
                        effective_parameters,
                        context,
                    )
            elif not effective_parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, str_statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, str_statement, context
                    )
            else:
                effective_parameters = cast(
                    "_CoreSingleExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute(
                        cursor, str_statement, effective_parameters, context
                    )
    
            if self._has_events or self.engine._has_events:
                self.dispatch.after_cursor_execute(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
            context.post_exec()
    
            result = context._setup_result_proxy()
    
        except BaseException as e:
>           self._handle_dbapi_exception(
                e, str_statement, effective_parameters, cursor, context
            )

/usr/local/lib/python3.11/site-packages/sqlalchemy/engine/base.py:1986: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.engine.base.Connection object at 0x7f562c8c4a50>
e = ProgrammingError('<class \'asyncpg.exceptions.UndefinedObjectError\'>: type "vector" does not exist')
statement = '\nCREATE TABLE user_embeddings (\n\tuser_id INTEGER NOT NULL, \n\tbrief_id VARCHAR NOT NULL, \n\tembedding VECTOR(153...d_at TIMESTAMP WITHOUT TIME ZONE NOT NULL, \n\tPRIMARY KEY (id), \n\tFOREIGN KEY(user_id) REFERENCES users (id)\n)\n\n'
parameters = ()
cursor = <sqlalchemy.dialects.postgresql.asyncpg.AsyncAdapt_asyncpg_cursor object at 0x7f562c7fe380>
context = <sqlalchemy.dialects.postgresql.asyncpg.PGExecutionContext_asyncpg object at 0x7f562c4d4a90>
is_sub_exec = False

    def _handle_dbapi_exception(
        self,
        e: BaseException,
        statement: Optional[str],
        parameters: Optional[_AnyExecuteParams],
        cursor: Optional[DBAPICursor],
        context: Optional[ExecutionContext],
        is_sub_exec: bool = False,
    ) -> NoReturn:
        exc_info = sys.exc_info()
    
        is_exit_exception = util.is_exit_exception(e)
    
        if not self._is_disconnect:
            self._is_disconnect = (
                isinstance(e, self.dialect.loaded_dbapi.Error)
                and not self.closed
                and self.dialect.is_disconnect(
                    e,
                    self._dbapi_connection if not self.invalidated else None,
                    cursor,
                )
            ) or (is_exit_exception and not self.closed)
    
        invalidate_pool_on_disconnect = not is_exit_exception
    
        ismulti: bool = (
            not is_sub_exec and context.executemany
            if context is not None
            else False
        )
        if self._reentrant_error:
            raise exc.DBAPIError.instance(
                statement,
                parameters,
                e,
                self.dialect.loaded_dbapi.Error,
                hide_parameters=self.engine.hide_parameters,
                dialect=self.dialect,
                ismulti=ismulti,
            ).with_traceback(exc_info[2]) from e
        self._reentrant_error = True
        try:
            # non-DBAPI error - if we already got a context,
            # or there's no string statement, don't wrap it
            should_wrap = isinstance(e, self.dialect.loaded_dbapi.Error) or (
                statement is not None
                and context is None
                and not is_exit_exception
            )
    
            if should_wrap:
                sqlalchemy_exception = exc.DBAPIError.instance(
                    statement,
                    parameters,
                    cast(Exception, e),
                    self.dialect.loaded_dbapi.Error,
                    hide_parameters=self.engine.hide_parameters,
                    connection_invalidated=self._is_disconnect,
                    dialect=self.dialect,
                    ismulti=ismulti,
                )
            else:
                sqlalchemy_exception = None
    
            newraise = None
    
            if (self.dialect._has_events) and not self._execution_options.get(
                "skip_user_error_events", False
            ):
                ctx = ExceptionContextImpl(
                    e,
                    sqlalchemy_exception,
                    self.engine,
                    self.dialect,
                    self,
                    cursor,
                    statement,
                    parameters,
                    context,
                    self._is_disconnect,
                    invalidate_pool_on_disconnect,
                    False,
                )
    
                for fn in self.dialect.dispatch.handle_error:
                    try:
                        # handler returns an exception;
                        # call next handler in a chain
                        per_fn = fn(ctx)
                        if per_fn is not None:
                            ctx.chained_exception = newraise = per_fn
                    except Exception as _raised:
                        # handler raises an exception - stop processing
                        newraise = _raised
                        break
    
                if self._is_disconnect != ctx.is_disconnect:
                    self._is_disconnect = ctx.is_disconnect
                    if sqlalchemy_exception:
                        sqlalchemy_exception.connection_invalidated = (
                            ctx.is_disconnect
                        )
    
                # set up potentially user-defined value for
                # invalidate pool.
                invalidate_pool_on_disconnect = (
                    ctx.invalidate_pool_on_disconnect
                )
    
            if should_wrap and context:
                context.handle_dbapi_exception(e)
    
            if not self._is_disconnect:
                if cursor:
                    self._safe_close_cursor(cursor)
                # "autorollback" was mostly relevant in 1.x series.
                # It's very unlikely to reach here, as the connection
                # does autobegin so when we are here, we are usually
                # in an explicit / semi-explicit transaction.
                # however we have a test which manufactures this
                # scenario in any case using an event handler.
                # test/engine/test_execute.py-> test_actual_autorollback
                if not self.in_transaction():
                    self._rollback_impl()
    
            if newraise:
                raise newraise.with_traceback(exc_info[2]) from e
            elif should_wrap:
                assert sqlalchemy_exception is not None
>               raise sqlalchemy_exception.with_traceback(exc_info[2]) from e

/usr/local/lib/python3.11/site-packages/sqlalchemy/engine/base.py:2363: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.engine.base.Connection object at 0x7f562c8c4a50>
dialect = <sqlalchemy.dialects.postgresql.asyncpg.PGDialect_asyncpg object at 0x7f562c8fee10>
context = <sqlalchemy.dialects.postgresql.asyncpg.PGExecutionContext_asyncpg object at 0x7f562c4d4a90>
statement = <sqlalchemy.dialects.postgresql.base.PGDDLCompiler object at 0x7f562c4d6b10>
parameters = [()]

    def _exec_single_context(
        self,
        dialect: Dialect,
        context: ExecutionContext,
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
    ) -> CursorResult[Any]:
        """continue the _execute_context() method for a single DBAPI
        cursor.execute() or cursor.executemany() call.
    
        """
        if dialect.bind_typing is BindTyping.SETINPUTSIZES:
            generic_setinputsizes = context._prepare_set_input_sizes()
    
            if generic_setinputsizes:
                try:
                    dialect.do_set_input_sizes(
                        context.cursor, generic_setinputsizes, context
                    )
                except BaseException as e:
                    self._handle_dbapi_exception(
                        e, str(statement), parameters, None, context
                    )
    
        cursor, str_statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )
    
        effective_parameters: Optional[_AnyExecuteParams]
    
        if not context.executemany:
            effective_parameters = parameters[0]
        else:
            effective_parameters = parameters
    
        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                str_statement, effective_parameters = fn(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
        if self._echo:
            self._log_info(str_statement)
    
            stats = context._get_cache_stats()
    
            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        effective_parameters,
                        batches=10,
                        ismulti=context.executemany,
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]",
                    stats,
                )
    
        evt_handled: bool = False
        try:
            if context.execute_style is ExecuteStyle.EXECUTEMANY:
                effective_parameters = cast(
                    "_CoreMultiExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor,
                        str_statement,
                        effective_parameters,
                        context,
                    )
            elif not effective_parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, str_statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, str_statement, context
                    )
            else:
                effective_parameters = cast(
                    "_CoreSingleExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
>                   self.dialect.do_execute(
                        cursor, str_statement, effective_parameters, context
                    )

/usr/local/lib/python3.11/site-packages/sqlalchemy/engine/base.py:1967: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.asyncpg.PGDialect_asyncpg object at 0x7f562c8fee10>
cursor = <sqlalchemy.dialects.postgresql.asyncpg.AsyncAdapt_asyncpg_cursor object at 0x7f562c7fe380>
statement = '\nCREATE TABLE user_embeddings (\n\tuser_id INTEGER NOT NULL, \n\tbrief_id VARCHAR NOT NULL, \n\tembedding VECTOR(153...d_at TIMESTAMP WITHOUT TIME ZONE NOT NULL, \n\tPRIMARY KEY (id), \n\tFOREIGN KEY(user_id) REFERENCES users (id)\n)\n\n'
parameters = ()
context = <sqlalchemy.dialects.postgresql.asyncpg.PGExecutionContext_asyncpg object at 0x7f562c4d4a90>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)

/usr/local/lib/python3.11/site-packages/sqlalchemy/engine/default.py:952: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.asyncpg.AsyncAdapt_asyncpg_cursor object at 0x7f562c7fe380>
operation = '\nCREATE TABLE user_embeddings (\n\tuser_id INTEGER NOT NULL, \n\tbrief_id VARCHAR NOT NULL, \n\tembedding VECTOR(153...d_at TIMESTAMP WITHOUT TIME ZONE NOT NULL, \n\tPRIMARY KEY (id), \n\tFOREIGN KEY(user_id) REFERENCES users (id)\n)\n\n'
parameters = ()

    def execute(self, operation, parameters=None):
>       self._adapt_connection.await_(
            self._prepare_and_execute(operation, parameters)
        )

/usr/local/lib/python3.11/site-packages/sqlalchemy/dialects/postgresql/asyncpg.py:585: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

awaitable = <coroutine object AsyncAdapt_asyncpg_cursor._prepare_and_execute at 0x7f562c9471c0>

    def await_only(awaitable: Awaitable[_T]) -> _T:
        """Awaits an async function in a sync method.
    
        The sync method must be inside a :func:`greenlet_spawn` context.
        :func:`await_only` calls cannot be nested.
    
        :param awaitable: The coroutine to call.
    
        """
        # this is called in the context greenlet while running fn
        current = getcurrent()
        if not getattr(current, "__sqlalchemy_greenlet_provider__", False):
            _safe_cancel_awaitable(awaitable)
    
            raise exc.MissingGreenlet(
                "greenlet_spawn has not been called; can't call await_only() "
                "here. Was IO attempted in an unexpected place?"
            )
    
        # returns the control to the driver greenlet passing it
        # a coroutine to run. Once the awaitable is done, the driver greenlet
        # switches back to this greenlet with the result of awaitable that is
        # then returned to the caller (or raised as error)
>       return current.parent.switch(awaitable)  # type: ignore[no-any-return,attr-defined] # noqa: E501
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

/usr/local/lib/python3.11/site-packages/sqlalchemy/util/_concurrency_py3k.py:132: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <bound method MetaData.create_all of MetaData()>, _require_await = False
args = (<sqlalchemy.engine.base.Connection object at 0x7f562c8c4a50>,)
kwargs = {}
context = <_AsyncIoGreenlet object at 0x7f562c81e880 (otid=0x7f564645ea90) dead>
switch_occurred = True
result = <coroutine object AsyncAdapt_asyncpg_cursor._prepare_and_execute at 0x7f562c9471c0>
value = None

    async def greenlet_spawn(
        fn: Callable[..., _T],
        *args: Any,
        _require_await: bool = False,
        **kwargs: Any,
    ) -> _T:
        """Runs a sync function ``fn`` in a new greenlet.
    
        The sync function can then use :func:`await_only` to wait for async
        functions.
    
        :param fn: The sync callable to call.
        :param \\*args: Positional arguments to pass to the ``fn`` callable.
        :param \\*\\*kwargs: Keyword arguments to pass to the ``fn`` callable.
        """
    
        result: Any
        context = _AsyncIoGreenlet(fn, getcurrent())
        # runs the function synchronously in gl greenlet. If the execution
        # is interrupted by await_only, context is not dead and result is a
        # coroutine to wait. If the context is dead the function has
        # returned, and its result can be returned.
        switch_occurred = False
        result = context.switch(*args, **kwargs)
        while not context.dead:
            switch_occurred = True
            try:
                # wait for a coroutine from await_only and then return its
                # result back to it.
>               value = await result
                        ^^^^^^^^^^^^

/usr/local/lib/python3.11/site-packages/sqlalchemy/util/_concurrency_py3k.py:196: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.asyncpg.AsyncAdapt_asyncpg_cursor object at 0x7f562c7fe380>
operation = '\nCREATE TABLE user_embeddings (\n\tuser_id INTEGER NOT NULL, \n\tbrief_id VARCHAR NOT NULL, \n\tembedding VECTOR(153...d_at TIMESTAMP WITHOUT TIME ZONE NOT NULL, \n\tPRIMARY KEY (id), \n\tFOREIGN KEY(user_id) REFERENCES users (id)\n)\n\n'
parameters = ()

    async def _prepare_and_execute(self, operation, parameters):
        adapt_connection = self._adapt_connection
    
        async with adapt_connection._execute_mutex:
            if not adapt_connection._started:
                await adapt_connection._start_transaction()
    
            if parameters is None:
                parameters = ()
    
            try:
                prepared_stmt, attributes = await adapt_connection._prepare(
                    operation, self._invalidate_schema_cache_asof
                )
    
                if attributes:
                    self.description = [
                        (
                            attr.name,
                            attr.type.oid,
                            None,
                            None,
                            None,
                            None,
                            None,
                        )
                        for attr in attributes
                    ]
                else:
                    self.description = None
    
                if self.server_side:
                    self._cursor = await prepared_stmt.cursor(*parameters)
                    self.rowcount = -1
                else:
                    self._rows = deque(await prepared_stmt.fetch(*parameters))
                    status = prepared_stmt.get_statusmsg()
    
                    reg = re.match(
                        r"(?:SELECT|UPDATE|DELETE|INSERT \d+) (\d+)",
                        status or "",
                    )
                    if reg:
                        self.rowcount = int(reg.group(1))
                    else:
                        self.rowcount = -1
    
            except Exception as error:
>               self._handle_exception(error)

/usr/local/lib/python3.11/site-packages/sqlalchemy/dialects/postgresql/asyncpg.py:563: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.asyncpg.AsyncAdapt_asyncpg_cursor object at 0x7f562c7fe380>
error = UndefinedObjectError('type "vector" does not exist')

    def _handle_exception(self, error):
>       self._adapt_connection._handle_exception(error)

/usr/local/lib/python3.11/site-packages/sqlalchemy/dialects/postgresql/asyncpg.py:513: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <AdaptedConnection <asyncpg.connection.Connection object at 0x7f562c810e50>>
error = UndefinedObjectError('type "vector" does not exist')

    def _handle_exception(self, error):
        if self._connection.is_closed():
            self._transaction = None
            self._started = False
    
        if not isinstance(error, AsyncAdapt_asyncpg_dbapi.Error):
            exception_mapping = self.dbapi._asyncpg_error_translate
    
            for super_ in type(error).__mro__:
                if super_ in exception_mapping:
                    translated_error = exception_mapping[super_](
                        "%s: %s" % (type(error), error)
                    )
                    translated_error.pgcode = translated_error.sqlstate = (
                        getattr(error, "sqlstate", None)
                    )
>                   raise translated_error from error
E                   sqlalchemy.exc.ProgrammingError: (sqlalchemy.dialects.postgresql.asyncpg.ProgrammingError) <class 'asyncpg.exceptions.UndefinedObjectError'>: type "vector" does not exist
E                   [SQL: 
E                   CREATE TABLE user_embeddings (
E                   	user_id INTEGER NOT NULL, 
E                   	brief_id VARCHAR NOT NULL, 
E                   	embedding VECTOR(1536) NOT NULL, 
E                   	source_text TEXT NOT NULL, 
E                   	embedding_type VARCHAR, 
E                   	metadata JSONB, 
E                   	id SERIAL NOT NULL, 
E                   	created_at TIMESTAMP WITHOUT TIME ZONE NOT NULL, 
E                   	updated_at TIMESTAMP WITHOUT TIME ZONE NOT NULL, 
E                   	PRIMARY KEY (id), 
E                   	FOREIGN KEY(user_id) REFERENCES users (id)
E                   )
E                   
E                   ]
E                   (Background on this error at: https://sqlalche.me/e/20/f405)

/usr/local/lib/python3.11/site-packages/sqlalchemy/dialects/postgresql/asyncpg.py:797: ProgrammingError
=========================== short test summary info ============================
ERROR tests/test_e2e/test_coaching_flow.py::TestCoachingFlowE2E::test_full_coaching_to_site_generation
======================== 21 warnings, 1 error in 6.32s =========================
